{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62c71c5-1ffd-46a0-a9c5-40be305f8c70",
   "metadata": {},
   "source": [
    "# Coeus AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636b0bf-21bc-4391-88ac-efc7cebfaf5d",
   "metadata": {},
   "source": [
    "## Selección de técnica de binarización\n",
    "1. Selección aleatoria de un conjunto de prueba\n",
    "2. Generación de imágenes con ambos métodos de binarización\n",
    "3. Predicción de OCR para tres conjuntos: normal, Otsu y adaptativa\n",
    "4. Evaluación de los métodos con métricas: Dice, Jaccard y Cosine\n",
    "5. Selección del mejor método de binarización: Adaptativa\n",
    "\n",
    "**Nota:** El proceso de diseño, evaluación y selección de la técnica de binarización se puede encontrar en la libreta [Preprocesamiento.ipynb](Preprocesamiento.ipynb)\n",
    "\n",
    "## Pre-procesamiento de imágenes\n",
    "1. Transformación del documento a escala de grises\n",
    "2. Reescalado de imagen por un factor $f$\n",
    "3. Eliminación de sombras (Blurred + (255 - abs diff de planos))\n",
    "4. Binarización Adaptativa\n",
    "5. Corrección de orientación (OpenCV o Tesseract)\n",
    "6. Recorte de bordes de fotografía/escaneo\n",
    "\n",
    "**Nota:** Todas las funciones necesarias para realizar el pre-procesamiento se pueden encontrar en [extras/preprocessing.py](extras/preprocessing.py), incluyendo la función \"preprocess\", que contiene el pipeline completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec6f2532-106e-4178-82d6-d982fea58b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tratamiento para el documento Ficheros_Represores_Martinez_Adame_Arturo_Martinez_Adame_Arturo-31-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_ACNR_militantes_Olea_Castaneyra_Rafel_Olea_Castaneyra_Rafael,_ACNR-19-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_Detenidos_Desaparecidos_Perez_Lopez_Martha_Perez_Lopez_Martha-21-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_Detenidos_Desaparecidos_Morales_Lopez_Delia_Morales_Lopez_Delia-23-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_Union_Campesina_Independiente,_fichas_UCI,_fichas-2-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_Brigada_Campesina_de_Ajusticiamiento_BCA_Brigada_Campesina_de_Ajusticiamiento-79-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_UAG_73-10-29_a_73-12-07_UAG,_fichas-134-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_FAR,_concentrado_general_FAR,_concentrado_general-157-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_UAG_76-11-16_a_77-03-19_UAG,_fichas-113-.JPG ha finalizado.\n",
      "El tratamiento para el documento Ficheros_PPUA_Fichas_PPUA,_Fichas-98-.JPG ha finalizado.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ejecutar esta celda solo si se desea realizar el pre-procesamiento a todos los documentos dentro de \"path_to_docs\".\n",
    "\"\"\"\n",
    "import os\n",
    "from cv2 import imread as cv2_imread\n",
    "from cv2 import imwrite as cv2_imwrite\n",
    "from extras.preprocessing import preprocess\n",
    "\n",
    "# Se define la ruta a los documentos\n",
    "path_to_docs = \"Datos/Evaluacion/original/\"\n",
    "\n",
    "# Se define la ruta en donde guardar los documentos procesados\n",
    "path_to_procs = \"Datos/Evaluacion/procesados/\"\n",
    "\n",
    "# Por cada imagen dentro de 'path_to_docs'\n",
    "for nombre_archivo in os.listdir(path_to_docs):\n",
    "    # Se define la ruta al documento\n",
    "    path_archivo = os.path.join(path_to_docs, nombre_archivo)\n",
    "    \n",
    "    # Se carga el documento con OpenCV\n",
    "    img = cv2_imread(path_archivo)\n",
    "    \n",
    "    # Se aplica el tratamiento (pre-procesamiento) al documento\n",
    "    \"\"\"\n",
    "    Nota: La función 'preprocess' permite seleccionar el tipo e intensidad de la binarización, así como el método de corrección de orientación.\n",
    "    Los valores por defecto son aquellos que reportaron mejores métricas durante la etapa de pruebas.\n",
    "    \"\"\"\n",
    "    procs_img = preprocess(img, binarization='adaptive', orientation='cv2', t=10)\n",
    "    \n",
    "    # Se genera la ruta al documento procesado\n",
    "    if os.path.exists(path_to_procs):\n",
    "        path_output = os.path.join(path_to_procs, nombre_archivo)\n",
    "    else:\n",
    "        os.mkdir(path_to_procs)\n",
    "        path_output = os.path.join(path_to_procs, nombre_archivo)\n",
    "    \n",
    "    # Se escribe el documento con OpenCV\n",
    "    cv2_imwrite(path_output, procs_img)\n",
    "    print(\"El tratamiento para el documento\",nombre_archivo,\"ha finalizado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81e6c57-d08b-4feb-890f-1779625292c0",
   "metadata": {},
   "source": [
    "## Extracción de OCR de las imágenes con motores seleccionados\n",
    "1. OCR a la imagen $i$ con Azure OCR\n",
    "2. OCR a la imagen $i$ con EasyOCR\n",
    "3. Selección del mejor texto de forma no-supervisada: métrica compuesta ponderada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c09f142-41ae-40c4-b3e4-1bccd574e7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo de transcripciones se ha creado con éxito: Datos/Evaluacion/predictions.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yibbtstll/venvs/CoeusAI/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EasyOCR de documento Ficheros_Represores_Martinez_Adame_Arturo_Martinez_Adame_Arturo-31-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_ACNR_militantes_Olea_Castaneyra_Rafel_Olea_Castaneyra_Rafael,_ACNR-19-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_Detenidos_Desaparecidos_Perez_Lopez_Martha_Perez_Lopez_Martha-21-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_Detenidos_Desaparecidos_Morales_Lopez_Delia_Morales_Lopez_Delia-23-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_Union_Campesina_Independiente,_fichas_UCI,_fichas-2-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_Brigada_Campesina_de_Ajusticiamiento_BCA_Brigada_Campesina_de_Ajusticiamiento-79-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_UAG_73-10-29_a_73-12-07_UAG,_fichas-134-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_FAR,_concentrado_general_FAR,_concentrado_general-157-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_UAG_76-11-16_a_77-03-19_UAG,_fichas-113-.JPG finalizado con éxito.\n",
      "EasyOCR de documento Ficheros_PPUA_Fichas_PPUA,_Fichas-98-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_Represores_Martinez_Adame_Arturo_Martinez_Adame_Arturo-31-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_ACNR_militantes_Olea_Castaneyra_Rafel_Olea_Castaneyra_Rafael,_ACNR-19-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_Detenidos_Desaparecidos_Perez_Lopez_Martha_Perez_Lopez_Martha-21-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_Detenidos_Desaparecidos_Morales_Lopez_Delia_Morales_Lopez_Delia-23-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_Union_Campesina_Independiente,_fichas_UCI,_fichas-2-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_Brigada_Campesina_de_Ajusticiamiento_BCA_Brigada_Campesina_de_Ajusticiamiento-79-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_UAG_73-10-29_a_73-12-07_UAG,_fichas-134-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_FAR,_concentrado_general_FAR,_concentrado_general-157-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_UAG_76-11-16_a_77-03-19_UAG,_fichas-113-.JPG finalizado con éxito.\n",
      "Azure OCR de documento Ficheros_PPUA_Fichas_PPUA,_Fichas-98-.JPG finalizado con éxito.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ejecutar esta celda solo si se desea extraer el texto de los documentos.\n",
    "\"\"\"\n",
    "from coeus import inference\n",
    "\n",
    "# Se define la ruta a los documentos\n",
    "path_to_docs = \"Datos/Evaluacion/original/\"\n",
    "\n",
    "# Se define la ruta en donde guardar los documentos procesados\n",
    "path_to_procs = \"Datos/Evaluacion/procesados/\"\n",
    "\n",
    "# Se define la ruta en donde guardar el JSON con el texto extraído\n",
    "path_to_predictions = \"Datos/Evaluacion/predictions.json\"\n",
    "\n",
    "# Realizando la predicción de texto: Azure + EasyOCR\n",
    "inference(path_to_docs, path_to_procs, path_to_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e50e2f-8711-436b-890b-68640b711f82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extracción de entidades\n",
    "1. Extracción de entidades con Spacy: es_core_news_lg\n",
    "2. Enriquecimiento de entidades de Spacy con DateParser\n",
    "3. Extracción de entidades con Azure NER\n",
    "4. Creación de un conjunto único: Spacy + DateParser + Azure NER\n",
    "5. Extracción de expediente con Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386cbfe2-c7cb-4c10-954f-3466a484e4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades del documento 0 : Ficheros_Represores_Martinez_Adame_Arturo_Martinez_Adame_Arturo-31-.JPG han sido procesadas.\n",
      "Entidades del documento 1 : Ficheros_ACNR_militantes_Olea_Castaneyra_Rafel_Olea_Castaneyra_Rafael,_ACNR-19-.JPG han sido procesadas.\n",
      "Entidades del documento 2 : Ficheros_Detenidos_Desaparecidos_Perez_Lopez_Martha_Perez_Lopez_Martha-21-.JPG han sido procesadas.\n",
      "Entidades del documento 3 : Ficheros_Detenidos_Desaparecidos_Morales_Lopez_Delia_Morales_Lopez_Delia-23-.JPG han sido procesadas.\n",
      "Entidades del documento 4 : Ficheros_Union_Campesina_Independiente,_fichas_UCI,_fichas-2-.JPG han sido procesadas.\n",
      "Entidades del documento 5 : Ficheros_Brigada_Campesina_de_Ajusticiamiento_BCA_Brigada_Campesina_de_Ajusticiamiento-79-.JPG han sido procesadas.\n",
      "Entidades del documento 6 : Ficheros_UAG_73-10-29_a_73-12-07_UAG,_fichas-134-.JPG han sido procesadas.\n",
      "Entidades del documento 7 : Ficheros_FAR,_concentrado_general_FAR,_concentrado_general-157-.JPG han sido procesadas.\n",
      "Entidades del documento 8 : Ficheros_UAG_76-11-16_a_77-03-19_UAG,_fichas-113-.JPG han sido procesadas.\n",
      "Entidades del documento 9 : Ficheros_PPUA_Fichas_PPUA,_Fichas-98-.JPG han sido procesadas.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "La función coeus.add_entities_json() realiza los 4 pasos descritos en la \n",
    "celda anterior.\n",
    "Ejecturar esta celda solo si se desea realizar el procedimiento de extracción y enriquecimiento de entidades.\n",
    "\"\"\"\n",
    "from coeus import add_entities_json\n",
    "\n",
    "credentials = {'key': \"dadc0fff23804ae0890878f9b74ea18d\",\n",
    "               'endpoint': \"https://hacktextocrcoueus.cognitiveservices.azure.com/\"}\n",
    "\n",
    "# Se define la ruta en donde se guardó el JSON con el texto extraído\n",
    "path_to_predictions = \"Datos/Evaluacion/predictions.json\"\n",
    "\n",
    "# Se define la ruta en donde se guardó el JSON con el texto extraído\n",
    "path_to_save = \"Datos/Evaluacion/predictions_entities.json\"\n",
    "\n",
    "add_entities_json(path_to_predictions, path_to_save, credentials) # Añadiendo las entidades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5db647f-057f-4528-be78-665015ac9c7d",
   "metadata": {},
   "source": [
    "## Generación de archivos CSV con el formato requerido.\n",
    "1. Toda la información sobre cada documento se encuentra en el archivo JSON generado en las celdas anteriores\n",
    "2. Se extraerá la información de dicho JSON para construir los archivos CSV solicitados.\n",
    "\n",
    "Formato para entrega de extracción de texto: \n",
    "\n",
    "| filename | text |\n",
    "| --- | ----------- |\n",
    "| file1.jpg | \"Exp-11-240-74 \\| texto\" |\n",
    "| file1.jpg | \"Exp-13-123-74 \\| texto\" |\n",
    "\n",
    "Formato para entrega de extracción de texto: \n",
    "\n",
    "| filename | label | class |\n",
    "| --- | --- | --- |\n",
    "| File1.jpg | Grupo Popular Guerrillero (GPG) | Organización |\n",
    "File1.jpg | 23/09/1965 | Fecha\n",
    "File1.jpg | Arturo Gámiz García | Persona\n",
    "File1.jpg | \"Madera, Chihuahua\" | Lugar\n",
    "\n",
    "**Nota:** Para evitar problemas a la hora de cargar el documento CSV (pues además de delimitadores también puede haber comas en el texto), se decidió utilizar el delimitador: |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0065073a-9192-4174-8775-af4890c5b1d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Datos/EjemplosEntregable/predictions_entities.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_616616/3019244151.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcoeus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson_to_csv_2a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_to_csv_2b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mjson_to_csv_2a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Datos/EjemplosEntregable/predictions_entities.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Datos/EjemplosEntregable/2A.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mjson_to_csv_2b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Datos/EjemplosEntregable/predictions_entities.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Datos/EjemplosEntregable/2B.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/CoeusAI/Coeus-AI/coeus.py\u001b[0m in \u001b[0;36mjson_to_csv_2a\u001b[0;34m(path_to_json, path_to_2a)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mjson_to_csv_2a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_2a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;31m# Se carga el archivo JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0mpredictions_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Datos/EjemplosEntregable/predictions_entities.json'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Ejecutar esta celda si se desea extraer los datos guardados en el archivo JSON, para posteriormente\n",
    "generar los entregables en formato CSV requeridos por el Hackathon.\n",
    "\"\"\"\n",
    "from coeus import json_to_csv_2a, json_to_csv_2b\n",
    "\n",
    "json_to_csv_2a(\"Datos/Evaluacion/predictions_entities.json\", \"Datos/EjemplosEntregable/2A.csv\")\n",
    "json_to_csv_2b(\"Datos/Evaluacion/predictions_entities.json\", \"Datos/EjemplosEntregable/2B.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
